{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining Oracle\n",
    "It is important that we pretrain the critic network before we dive deep into training the actor itself. Let's do exactly that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "f = h5py.File(\"/media/dev/New Volume/projects/RecNN/static_dataset.hdf5\", \"r\")\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "frame_size = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateRepresentation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StateRepresentation, self).__init__()\n",
    "        self.lin = nn.Sequential(\n",
    "            # 128 - embed size, 1 - rating size\n",
    "            nn.Linear(frame_size * (128 + 1), 256),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, state):\n",
    "        # apply state represemtation module\n",
    "        state = self.lin(state)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.state_rep = StateRepresentation().to(cuda)\n",
    "        \n",
    "        # self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear1 = nn.Linear(256 + 128, hidden_size) #state rep + action + rating\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, enc_state, action):\n",
    "        x = torch.cat([enc_state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_net  = Critic(256, 128, 320).to(cuda)\n",
    "target_value_net  = Critic(256, 128, 320).to(cuda)\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "value_lr  = 10e-5\n",
    "value_optimizer  = optim.Adam(value_net.parameters(),  lr=value_lr)\n",
    "value_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_update(batch, \n",
    "           gamma = 0.99,\n",
    "           min_value=-5,\n",
    "           max_value=5,\n",
    "           soft_tau=1e-2):\n",
    "    \n",
    "    state, action, reward, _, _ = batch\n",
    "\n",
    "    enc_state = value_net.state_rep(state)\n",
    "    value = value_net(enc_state, action)\n",
    "    value_loss = value_criterion(value, reward)\n",
    "    \n",
    "    T_loss = torch.tensor(0)\n",
    "    \n",
    "    # you can uncomment these lines and see how the target network learns\n",
    "    # it will work 2 times slower tho\n",
    "    # T_enc_state = target_value_net.state_rep(*state)\n",
    "    # T_value = target_value_net(enc_state, action)\n",
    "    # T_loss = value_criterion(T_value, reward)\n",
    "    \n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward(retain_graph=True)\n",
    "    value_optimizer.step()\n",
    "\n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "            )\n",
    "\n",
    "    losses = [value_loss.item(), T_loss.item()] \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai')\n",
    "\n",
    "def plot(losses, T_losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses, '-b')\n",
    "    plt.plot(T_losses, '-w')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3bc6c809ef4fa2b989de0a62be091e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3691), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebf123997054c0b869bb0950e27c505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "T_losses = []\n",
    "\n",
    "n_epochs = 3\n",
    "batch_size = 1000\n",
    "n_batches = (f['state'].shape[0] // batch_size) + 1\n",
    "\n",
    "batch_bar = tqdm(total=n_batches)\n",
    "epoch_bar = tqdm(total=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(*args):\n",
    "    args = [torch.tensor(np.array(arg).astype(np.float)).to(cuda).float() for arg in args]\n",
    "    return args\n",
    "\n",
    "batch = []\n",
    "for epoch in range(4):\n",
    "    epoch_bar.update(1)\n",
    "    for i in range(n_batches):\n",
    "        batch_bar.update(1)\n",
    "        batch = [f[key][i*batch_size:(i+1)*batch_size] for key in\n",
    "                 ['state', 'action', 'reward', 'next_state', 'done']]\n",
    "        batch = prepare_batch(*batch)\n",
    "        loss = value_update(batch)\n",
    "        losses.append(loss[0])\n",
    "        T_losses.append(loss[1])\n",
    "        \n",
    "        batch = []\n",
    "        \n",
    "    batch_bar.refresh()    \n",
    "    plot(losses, T_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_state = torch.tensor([[ 0.8234, -0.9226, -0.4121, -0.5340, -0.8833,  0.7875,  0.6483,  0.9270,\n",
    "         0.7166,  0.3647, -0.6192,  0.4958,  0.2272,  0.5348,  0.8607, -0.8804,\n",
    "        -0.2465, -0.4283, -0.4022,  0.1800,  0.5892,  0.3719, -0.8434,  0.8415,\n",
    "         0.2611, -0.3241,  0.9081, -0.8466, -0.9381,  0.5714,  0.8995, -0.7719,\n",
    "        -0.8924, -0.8616,  0.6031,  0.5534, -0.9667,  0.7193,  0.5872, -0.5237,\n",
    "        -0.8892, -0.2707, -0.0501,  0.0757,  0.7951,  0.9076, -0.4727, -0.8728,\n",
    "        -0.6557,  0.5244, -0.8006, -0.8477, -0.8758,  0.1813, -0.8301,  0.8902,\n",
    "         0.0885,  0.9561, -0.4246, -0.5680,  0.3708, -0.2754, -0.1325, -0.8910,\n",
    "         0.9343, -0.5149, -0.1698,  0.4403, -0.8597,  0.2069, -0.0524,  0.9302,\n",
    "         0.0121,  0.0965,  0.0442,  0.9579,  0.9277, -0.7446,  0.8137, -0.9641,\n",
    "         0.7567, -0.8799,  0.3058, -0.3211,  0.4471, -0.6690,  0.8665,  0.8037,\n",
    "        -0.1293, -0.2239,  0.7319,  0.4257,  0.4706, -0.4224, -0.9544, -0.9011,\n",
    "        -0.3293,  0.7725,  0.3611, -0.7188, -0.6263,  0.1799,  0.6883, -0.1732,\n",
    "        -0.6490,  0.2394,  0.8581, -0.4586,  0.2242, -0.0524,  0.6026,  0.5842,\n",
    "        -0.7486,  0.0851, -0.8351,  0.8072, -0.5694,  0.3146, -0.4573,  0.5108,\n",
    "         0.7644, -0.8456,  0.7863,  0.4402, -0.1834, -0.2558, -0.2851,  0.9048,\n",
    "        -0.8460, -0.8722,  0.8794,  0.5680, -0.8479, -0.9500, -0.9752, -0.9044,\n",
    "         0.6765, -0.0330, -0.5040, -0.1801, -0.8043,  0.7728,  0.3033,  0.9752,\n",
    "        -0.4627,  0.2142,  0.4854,  0.5244, -0.9714,  0.7670, -0.9627, -0.2361,\n",
    "        -0.6224,  0.6705, -0.8673, -0.6650,  0.4627, -0.8737,  0.4474, -0.3924,\n",
    "        -0.9359, -0.0336,  0.9321, -0.7822,  0.9091,  0.7381,  0.9203,  0.9123,\n",
    "         0.8177, -0.9623,  0.7752, -0.5572,  0.8420, -0.9806,  0.1019, -0.5598,\n",
    "         0.5590, -0.5500,  0.0432,  0.3796, -0.0150, -0.2686, -0.6205,  0.8671,\n",
    "         0.6566,  0.5327,  0.4598, -0.5333,  0.9192,  0.4521,  0.8336,  0.0417,\n",
    "        -0.2890, -0.8790,  0.9067, -0.7993, -0.8090, -0.4098, -0.8387, -0.1831,\n",
    "         0.9101,  0.5435,  0.6865,  0.5567,  0.8913,  0.4114, -0.0339, -0.8270,\n",
    "        -0.7629,  0.8433, -0.4769,  0.8089,  0.0494,  0.5300, -0.6053, -0.0521,\n",
    "        -0.9758, -0.6356, -0.7258,  0.2259, -0.7995,  0.8615, -0.7936,  0.8672,\n",
    "        -0.6861,  0.7564, -0.0775, -0.5616,  0.3289,  0.3835,  0.7120,  0.6992,\n",
    "        -0.7833, -0.4280, -0.2882,  0.7869,  0.4963, -0.9954, -0.1500,  0.8808,\n",
    "        -0.9319,  0.6018, -0.4127, -0.3618, -0.8479,  0.1121,  0.3557, -0.0873,\n",
    "        -0.3617,  0.3186, -0.7167, -0.9193,  0.0317,  0.9799, -0.0764, -0.7328]]).to(cuda).float()\n",
    "\n",
    "dum_action = torch.tensor(np.random.normal(2, 0.2, [1, 128]) ).to(cuda).float()\n",
    "scores = target_value_net(dum_state, dum_action)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
