{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is very important!\n",
    "You need to generate the dataset yourself or download the existing one! You can do dynamic generation on the go, but it usually takes around 1.5 hours to go through the dataset. I prefer to use statically generated dataset because it allows to iterate throught the dataset in am matter of 10 minutes. Frame size in the number of actions you want to be in the state (the number of movies rated). I have chosen it to be 10, if you want another number you will have to generate it yourself. Link to the google drive is in the readme.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "cuda = torch.device('cpu')\n",
    "frame_size = 10\n",
    "ratings = pd.read_csv('../data/ml-20m/ratings_lite.csv')\n",
    "movies = pickle.load(open('../data/infos_pca128.pytorch', 'rb'))\n",
    "infos_web = json.load(open('../data/infos.json')) \n",
    "\n",
    "# credits: KnightofK9\n",
    "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda i: 2 * (i - 2.5))\n",
    "users = ratings[[\"userId\",\"movieId\"]].groupby([\"userId\"]).size()\n",
    "users = users[users >= frame_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = users[-100:]\n",
    "train_users = users[:-100]\n",
    "\n",
    "train_ratings = ratings[ratings[\"userId\"].isin(train_users.index)]\n",
    "test_ratings = ratings[ratings[\"userId\"].isin(test_users.index)]\n",
    "\n",
    "train_ratings = train_ratings.sort_values(by=[\"userId\", \"timestamp\"]).drop(columns=[\"timestamp\"]).set_index(\"userId\")\n",
    "test_ratings = test_ratings.sort_values(by=[\"userId\", \"timestamp\"]).drop(columns=[\"timestamp\"]).set_index(\"userId\")\n",
    "\n",
    "for i in movies.keys():\n",
    "    movies[i] = movies[i].to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "n_iter = 1\n",
    "n_batch = 1\n",
    "n_user = 0\n",
    "\n",
    "\n",
    "def get_minibatch(df, idx):\n",
    "    user_ratings = df[idx:frame_size + idx + 1]\n",
    "    user_ratings = user_ratings[[\"movieId\", \"rating\"]].values\n",
    "\n",
    "    chosen_movie = user_ratings[:, 0][-1] \n",
    "    chosen_movie = movies[chosen_movie] # action\n",
    "    chosen_rating = user_ratings[:, 1][-1] # reward\n",
    "    films_watched = user_ratings[:, 0][:-1]\n",
    "    watched_rating = user_ratings[:, 1][:-1] # state\n",
    "    watched_infos = [movies[i] for i in films_watched] # state\n",
    "    watched_infos = torch.stack(watched_infos)\n",
    "    next_infos = torch.cat((watched_infos[1:], chosen_movie.unsqueeze(0)), 0)\n",
    "    next_rating = watched_rating[1:].tolist()\n",
    "    next_rating.append(chosen_rating)\n",
    "    next_rating = torch.tensor(next_rating)\n",
    "\n",
    "    # state action reward next_state done\n",
    "    return [(watched_infos, watched_rating), chosen_movie, chosen_rating,\n",
    "                  (next_infos, next_rating), idx + 1 == size]\n",
    "\n",
    "\n",
    "batch_bar = tqdm(total=len(train_users))\n",
    "batch = []\n",
    "batch_size = 100\n",
    "\n",
    "for user, df in train_ratings.groupby(level=0):\n",
    "    batch_bar.update(1)\n",
    "    n_user += 1\n",
    "    size = max(len(df) - frame_size, 0)\n",
    "    for idx in range(0, size):\n",
    "        if np.random.rand() < 0.8:  # intake percents\n",
    "            continue\n",
    "        batch.append(get_minibatch(df, idx))\n",
    "    \n",
    "    # if the memory error pops up, change the number below\n",
    "    # 8gb ram = 5000\n",
    "    # 16gb ram = 10000\n",
    "    # 32gb ram = 30000\n",
    "    if n_user % 10000 == 0:\n",
    "        pickle.dump(batch, open('../data/batches/batch_{}.p'.format(n_batch), 'wb'))\n",
    "        n_batch += 1\n",
    "        del batch\n",
    "        batch = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(batch, open('../data/batches/batch_{}.p'.format(n_batch), 'wb'))\n",
    "n_batch += 1\n",
    "del batch\n",
    "batch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H5PY integration\n",
    "p.s. restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "h5 = h5py.File(\"*path to where ypu want to save it*\", \"w\")\n",
    "idx = 0\n",
    "# datasets:\n",
    "# ds_state (float) (None, (frame_size + 1) * embed_size): (None, 1290)\n",
    "# ds_action (float) (None, embed_size): (None, 128)\n",
    "# ds_reward (int4) (None)\n",
    "# ds_next_state (float) (None, (frame_size + 1) * embed_size): (None, 1290)\n",
    "# ds_done (bool) (None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_state = h5.create_dataset(\"state\", (0, 1290), maxshape=(None, 1290), dtype='f', chunks=True, compression=\"lzf\")\n",
    "ds_action = h5.create_dataset(\"action\", (0, 128), maxshape=(None, 128), dtype='f', chunks=True,  compression=\"lzf\")\n",
    "ds_reward = h5.create_dataset(\"reward\", (0, ), maxshape=(None,), dtype='i1',  chunks=True,  compression=\"lzf\")\n",
    "ds_next_state = h5.create_dataset(\"next_state\", (0, 1290), maxshape=(None, 1290), dtype='f',  chunks=True, compression=\"lzf\")\n",
    "ds_done = h5.create_dataset(\"done\", (0, ), maxshape=(None,), dtype='?', chunks=True,  compression=\"lzf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# frame size you've chosen\n",
    "# must match with the number in the upper snippet\n",
    "frame_size = 10\n",
    "\n",
    "for j in tqdm(range(1,15)):\n",
    "    f = pickle.load(open('../data/batches/batch_{}.p'.format(j), 'rb'))\n",
    "    [i.resize([len(f) + i.shape[0], i.shape[1]]) for i in [ds_state,\n",
    "                                                ds_action, ds_next_state ]]\n",
    "    [i.resize([len(f) + i.shape[0]]) for i in [ds_reward, ds_done]]\n",
    "\n",
    "\n",
    "    for i in tqdm(f):\n",
    "        infos, ratings = i[0]\n",
    "        # frame_size, embed_size -> frame_size * embed_size\n",
    "        infos = infos.view(-1).numpy()\n",
    "        state = np.concatenate([infos, ratings])\n",
    "\n",
    "        action = i[1].numpy()\n",
    "        reward = i[2]\n",
    "\n",
    "        next_infos, next_ratings = i[3]\n",
    "        next_infos = next_infos.view(-1).numpy()\n",
    "        next_state = np.concatenate([next_infos, next_ratings])\n",
    "        done = i[4]\n",
    "\n",
    "        ds_state[idx] = state.astype('float16')\n",
    "        ds_action[idx] = action.astype('float16')\n",
    "        ds_reward[idx] = reward.astype('int8')\n",
    "        ds_next_state[idx] = next_state.astype('float16')\n",
    "        ds_done[idx] = done\n",
    "\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "f = h5py.File(\"*your path here*\", \"r\")\n",
    "#/media/dev/New Volume/projects/RecNN/static_dataset.hdf5\n",
    "#f = h5\n",
    "\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "def prepare_batch(*args):\n",
    "    args = [torch.tensor(np.array(arg).astype(np.float)).to(cuda) for arg in args]\n",
    "    return args\n",
    "\n",
    "\n",
    "batch = []\n",
    "batch_size = 5000\n",
    "losses = []\n",
    "T_losses = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(f['state'].shape[0] // batch_size)):\n",
    "    batch = [f[key][i*batch_size:(i+1)*batch_size] for key in\n",
    "             ['state', 'action', 'reward', 'next_state', 'done']]\n",
    "    \n",
    "    batch = prepare_batch(*batch)\n",
    "    batch = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
