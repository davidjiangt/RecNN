{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation\n",
    "You can do dynamic generation on the go, but it usually takes around 1.5 hours to go through the dataset. I prefer to use statically generated dataset because it allows to iterate throught the dataset in am matter of 4 minutes. Frame size in the number of actions you want to be in the state (the number of movies rated). I have chosen it to be 10, if you want another number you will have to generate it yourself. Link to the google drive is in the readme.md\n",
    "\n",
    "\n",
    "## This is a mandatory thing to do, you can download the existing dataset here: [Link](https://drive.google.com/open?id=1pPf-7AmUVceVfgfmKEJ6ireEDKEJHw-7)\n",
    "\n",
    "\n",
    "\n",
    "### Things you will need to download:\n",
    "- [Movie embeddings](https://drive.google.com/open?id=1kTyu05ZmtP2MA33J5hWdX8OyUYEDW4iI) or you can generate them yourself\n",
    "- [State Representation](https://drive.google.com/open?id=1DuNvPQ8pIxmZEFGNtXRSRxRcoWXU_0cO) if you want to generate the dataset LITE by encoding sequential features into lower dimensions 1290 -> 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Trim Ratings\n",
    "Exlude films with frequency <50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ratings = pd.read_csv(\"../data/ml-20m/ratings.csv\")\n",
    "s = pd.Series(ratings['movieId'].value_counts())\n",
    "# here is the value you can change\n",
    "to_ignore = s.loc[s.where(lambda s: s <= 50).isna()].index.values\n",
    "ratings = ratings[ratings['movieId'].isin(to_ignore)]\n",
    "ratings.to_csv('../data/ml-20m/ratings_lite.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Genaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "## Settings here!\n",
    "SMALL_STATE = True \n",
    "frame_size = 10\n",
    "batch_size = 1000\n",
    "## End settings\n",
    "\n",
    "cuda = torch.device('cpu')\n",
    "ratings = pd.read_csv('../data/ml-20m/ratings.csv')\n",
    "movies = pickle.load(open('../data/infos_pca128.pytorch', 'rb'))\n",
    "\n",
    "# credits: KnightofK9\n",
    "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda i: 2 * (i - 2.5))\n",
    "users = ratings[[\"userId\",\"movieId\"]].groupby([\"userId\"]).size()\n",
    "users = users[users >= frame_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['movieId'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.sort_values(by=[\"userId\", \"timestamp\"]).drop(columns=[\"timestamp\"]).set_index(\"userId\")\n",
    "\n",
    "for i in movies.keys():\n",
    "    movies[i] = movies[i].to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if SMALL_STATE is False, there is no need to run this cell\n",
    "import torch.nn as nn\n",
    "\n",
    "class StateRepresentation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StateRepresentation, self).__init__()\n",
    "        self.lin = nn.Sequential(\n",
    "            # 128 - embed size, 1 - rating size\n",
    "            nn.Linear(frame_size * (128 + 1), 256),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, state):\n",
    "        # apply state represemtation module\n",
    "        state = self.lin(state)\n",
    "        return state\n",
    "    \n",
    "state_rep = StateRepresentation()\n",
    "state_rep.load_state_dict(torch.load('../models/state_rep.pt'))\n",
    "state_rep.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "h5 = h5py.File(\"test.hdf5\", \"w\")\n",
    "idx = 0\n",
    "# datasets:\n",
    "# ds_state (float) (None, (frame_size + 1) * embed_size): (None, 1290)\n",
    "# ds_action (float) (None, embed_size): (None, 128)\n",
    "# ds_reward (int4) (None)\n",
    "# ds_next_state (float) (None, (frame_size + 1) * embed_size): (None, 1290)\n",
    "# ds_done (bool) (None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ratings = h5.create_dataset(\"ratings\", (0, 11), maxshape=(None, 256), dtype='int8', chunks=True, compression=\"lzf\")\n",
    "ds_movies = h5.create_dataset(\"movies\", (0, 11), maxshape=(None, 256), dtype='int32',  chunks=True, compression=\"lzf\")\n",
    "\n",
    "ds_done = h5.create_dataset(\"done\", (0, ), maxshape=(None,), dtype='?', chunks=True,  compression=\"lzf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "n_iter = 1\n",
    "n_batch = 0\n",
    "n_user = 0\n",
    "\n",
    "\n",
    "def get_minibatch(df, idx):\n",
    "    user_ratings = df[idx:frame_size + idx + 1]\n",
    "    user_ratings = user_ratings[[\"movieId\", \"rating\"]].values\n",
    "\n",
    "    movies = user_ratings[:, 0]\n",
    "    ratings = user_ratings[:, 1]\n",
    "\n",
    "    # state action reward next_state done\n",
    "    return [movies, ratings, idx + 1 == size]\n",
    "\n",
    "\n",
    "batch_bar = tqdm(total=len(users))\n",
    "batch = []\n",
    "\n",
    "g_idx = 0\n",
    "\n",
    "for user in ratings.index.unique():\n",
    "    df = ratings.loc[user]\n",
    "    batch_bar.update(1)\n",
    "    n_batch += 1\n",
    "    size = max(len(df) - frame_size, 0)\n",
    "    for idx in range(0, size):\n",
    "        # another value you can tweak!\n",
    "        if np.random.rand() < 0.8:  # intake percents\n",
    "            continue\n",
    "        batch.append(get_minibatch(df, idx))\n",
    "        \n",
    "        if len(batch) % batch_size == 0:\n",
    "            \n",
    "            [i.resize([len(batch) + i.shape[0], i.shape[1]]) for i in [ds_ratings, ds_movies]]\n",
    "            [i.resize([len(batch) + i.shape[0]]) for i in [ds_done]]\n",
    "            \n",
    "            for i in batch:\n",
    "                movies, ratings_, done = i\n",
    "                # frame_size, embed_size -> frame_size * embed_size\n",
    "                # infos = infos.view(-1).numpy()\n",
    "\n",
    "                movies = np.array(movies)\n",
    "                ratings_ = np.array(ratings_)\n",
    "                done = np.array(done)\n",
    "\n",
    "                ds_movies[g_idx] = movies.astype('int32')\n",
    "                ds_ratings[g_idx] = ratings_.astype('int8')\n",
    "                ds_done[g_idx] = done.astype('?')\n",
    "                #ds_next_state[g_idx] = next_state.astype('float16')\n",
    "                #ds_done[g_idx] = done\n",
    "                g_idx+=1\n",
    "            \n",
    "            del batch\n",
    "            batch = []\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "movie_ref = pickle.load(open('../data/infos_pca128.pytorch', 'rb'))\n",
    "\n",
    "f = h5py.File(\"test.hdf5\", \"r\")\n",
    "\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "def prepare_batch(*args):\n",
    "    args = [torch.tensor(np.array(arg).astype(np.float)).to(cuda) for arg in args]\n",
    "    return args\n",
    "\n",
    "\n",
    "batch_size = 5000\n",
    "losses = []\n",
    "T_losses = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(f['done'].shape[0] // batch_size)):\n",
    "    movies, ratings, done = [f[key][i*batch_size:(i+1)*batch_size] for key in\n",
    "             ['movies', 'ratings', 'done']]\n",
    "    \n",
    "    movies, ratings, done = [torch.tensor(i.astype('float32')) for i in [movies, ratings, done]]\n",
    "    movies_tensor = torch.stack([torch.stack([movie_ref[int(i)] for i in ts]) for ts in movies])\n",
    "    \n",
    "    state = torch.cat([movies_tensor[:, :-1, :].view(state.size(0), -1),\n",
    "                       ratings[:, :-1]], 1)\n",
    "    next_state = torch.cat([movies_tensor[:, 1:, :].view(state.size(0), -1),\n",
    "                            ratings[:, 1:]], 1)\n",
    "    action = movies_tensor[:, -1]\n",
    "    reward = ratings[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
