{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "\n",
    "cuda = torch.device('cpu')\n",
    "frame_size = 10\n",
    "batch_size = 1 # only 1 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "movies = pickle.load(open('../data/infos_pca128.pytorch', 'rb'))\n",
    "infos_web = json.load(open('../data/infos.json')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in movies.keys():\n",
    "    movies[i] = movies[i].to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateRepresentation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StateRepresentation, self).__init__()\n",
    "        self.lin = nn.Sequential(\n",
    "            # 128 - embed size, 1 - rating size\n",
    "            nn.Linear(frame_size * (128 + 1), 256),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, info, ratings):\n",
    "        # raw_size - size of the raw movie info. Constant = 2591\n",
    "        # embed_size - size of an ebedded movie. Constant = 64\n",
    "        # raw -> embed via embeddings module defined above\n",
    "        # input: currently info is batch_size x frame_size x raw_size\n",
    "        # step 1: tramsform info to batch_size x (frame_size * embed_size)\n",
    "        info = info.view(batch_size, frame_size * 128)\n",
    "        # step 2: stack info with ratings. stacked: batch_size x (embed_size + 1)\n",
    "        stacked = torch.cat([info, ratings], 1)\n",
    "        # step 3: apply state represemtation module\n",
    "        state = self.lin(stacked)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        self.state_rep = StateRepresentation()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, num_actions)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, info, rewards):\n",
    "        state = self.state_rep(info, rewards)\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = torch.tanh(self.linear3(x))\n",
    "        return state, x\n",
    "    \n",
    "    def get_action(self, info, rewards):\n",
    "        state, action = self.forward(info, rewards)\n",
    "        return state, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        action = torch.squeeze(action)\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "value_net  = Critic(256, 128, 320).to(cuda)\n",
    "policy_net = Actor(256, 128, 192).to(cuda)\n",
    "value_net.load_state_dict(torch.load(\"../models/value.pt\", map_location='cpu'))\n",
    "policy_net.load_state_dict(torch.load(\"../models/policy.pt\", map_location='cpu'))\n",
    "value_net.eval()\n",
    "policy_net.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_ids = [1732, 172, 370, 1639, 1380, 2054, 471, 2502, 1625, 2001]\n",
    "watched_ratings = torch.tensor([4.0, -3.0, -3.0, 2.0, 3.0, -2.0, 3.0, 1.0, 0.0, -1.0]).to(cuda).unsqueeze(0).float()\n",
    "watched_infos = [movies[i] for i in watched_ids] \n",
    "watched_infos = torch.cat(watched_infos).unsqueeze(0)\n",
    "enc_state, action = policy_net(watched_infos, watched_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9985, -0.9969,  0.9973, -0.9970, -0.9986, -0.9968, -0.9970, -0.9993,\n",
       "         -0.9966, -0.9953, -0.9994, -0.9990, -0.9992, -0.9925, -0.9973, -0.9991,\n",
       "         -0.9986, -0.9967, -0.9962, -0.9967, -0.9971, -0.9966,  0.7486, -0.9983,\n",
       "         -0.9938, -0.9993, -0.9943, -0.9988, -0.9951,  0.9997, -0.9969, -0.9994,\n",
       "          0.9977, -0.9935, -0.9993,  0.9988, -0.9990, -0.9986,  0.9983,  0.5878,\n",
       "         -0.9795, -0.9975,  0.0671, -0.9976, -0.9993, -0.9992, -0.9970, -0.9964,\n",
       "          0.8853, -0.9967, -0.9966, -0.9948, -0.9954,  0.9823, -0.9990,  0.9873,\n",
       "         -0.9997, -0.9993, -0.9930, -0.9982, -0.3362, -0.9938, -0.9922, -0.9955,\n",
       "         -0.9971,  0.9997,  0.9988, -0.9993, -0.9989, -0.9710,  0.9949, -0.9990,\n",
       "         -0.9954,  0.9978, -0.9994, -0.9944, -0.9970, -0.9937, -0.9984,  0.9967,\n",
       "         -0.9955, -0.9990, -0.9992, -0.9989, -0.9993, -0.9974, -0.9963, -0.9993,\n",
       "         -0.9911, -0.9990,  0.9983,  0.9981, -0.9991, -0.9993, -0.9993, -0.9991,\n",
       "         -0.9981, -0.9991, -0.9921, -0.9958, -0.9886, -0.9991, -0.9990, -0.9996,\n",
       "         -0.9946, -0.9988, -0.9948, -0.9971, -0.9850,  0.9981, -0.9983, -0.9992,\n",
       "         -0.9991, -0.9965, -0.9950, -0.9994, -0.9993, -0.9960, -0.9991, -0.9956,\n",
       "         -0.9854,  0.9899, -0.9994, -0.9975, -0.9987, -0.9981, -0.9977, -0.9986]],\n",
       "       grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUCKFUCKFUCK\n"
     ]
    }
   ],
   "source": [
    "print(\"FUCKFUCKFUCK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
